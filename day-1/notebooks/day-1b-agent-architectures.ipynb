{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:45.715285Z","iopub.execute_input":"2025-11-11T23:32:45.715612Z","iopub.status.idle":"2025-11-11T23:32:45.720892Z","shell.execute_reply.started":"2025-11-11T23:32:45.715583Z","shell.execute_reply":"2025-11-11T23:32:45.720109Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:47:49.896087Z","iopub.execute_input":"2025-11-11T23:47:49.896892Z","iopub.status.idle":"2025-11-11T23:47:50.154903Z","shell.execute_reply.started":"2025-11-11T23:47:49.896866Z","shell.execute_reply":"2025-11-11T23:47:50.154145Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:48:01.291904Z","iopub.execute_input":"2025-11-11T23:48:01.292501Z","iopub.status.idle":"2025-11-11T23:48:40.350541Z","shell.execute_reply.started":"2025-11-11T23:48:01.292476Z","shell.execute_reply":"2025-11-11T23:48:40.349669Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:49:34.016619Z","iopub.execute_input":"2025-11-11T23:49:34.018056Z","iopub.status.idle":"2025-11-11T23:49:34.022672Z","shell.execute_reply.started":"2025-11-11T23:49:34.018022Z","shell.execute_reply":"2025-11-11T23:49:34.021809Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:51:37.369844Z","iopub.execute_input":"2025-11-11T23:51:37.370181Z","iopub.status.idle":"2025-11-11T23:51:37.376105Z","shell.execute_reply.started":"2025-11-11T23:51:37.370154Z","shell.execute_reply":"2025-11-11T23:51:37.375270Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:52:05.636383Z","iopub.execute_input":"2025-11-11T23:52:05.637126Z","iopub.status.idle":"2025-11-11T23:52:05.642438Z","shell.execute_reply.started":"2025-11-11T23:52:05.637100Z","shell.execute_reply":"2025-11-11T23:52:05.641706Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:52:42.923605Z","iopub.execute_input":"2025-11-11T23:52:42.924462Z","iopub.status.idle":"2025-11-11T23:52:42.929758Z","shell.execute_reply.started":"2025-11-11T23:52:42.924431Z","shell.execute_reply":"2025-11-11T23:52:42.928891Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:52:57.768545Z","iopub.execute_input":"2025-11-11T23:52:57.768863Z","iopub.status.idle":"2025-11-11T23:53:11.206809Z","shell.execute_reply.started":"2025-11-11T23:52:57.768839Z","shell.execute_reply":"2025-11-11T23:53:11.205913Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are rapidly converging with artificial intelligence (AI), promising to unlock unprecedented computational power and revolutionize AI capabilities. This fusion, often termed Quantum AI, is poised to tackle problems currently intractable for classical computers, leading to breakthroughs across various sectors.\n\nHere's a concise summary of the key points regarding advancements in quantum computing and their implications for AI:\n\n*   **Accelerated AI:** Quantum computers, leveraging superposition, can process data and develop algorithms much faster, leading to significant speedups in AI tasks like pattern recognition and complex simulations.\n*   **Enhanced Optimization:** Quantum computing excels at solving optimization problems, directly benefiting AI applications such as resource allocation, predictive modeling, and recommendation systems.\n*   **Hardware Progress & Error Correction:** Significant strides are being made in developing stable, scalable quantum hardware and implementing crucial error correction techniques, paving the way for reliable quantum computers.\n*   **Transformative Use Cases & Hybrid Approaches:** Quantum AI is set to revolutionize fields like healthcare (drug discovery, personalized medicine) and finance, with hybrid quantum-classical systems expected to be the primary approach in the near future.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:54:49.869689Z","iopub.execute_input":"2025-11-11T23:54:49.870023Z","iopub.status.idle":"2025-11-11T23:54:49.875855Z","shell.execute_reply.started":"2025-11-11T23:54:49.869992Z","shell.execute_reply":"2025-11-11T23:54:49.875035Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:54:55.219070Z","iopub.execute_input":"2025-11-11T23:54:55.219786Z","iopub.status.idle":"2025-11-11T23:54:55.224861Z","shell.execute_reply.started":"2025-11-11T23:54:55.219759Z","shell.execute_reply":"2025-11-11T23:54:55.223997Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:55:13.150751Z","iopub.execute_input":"2025-11-11T23:55:13.151054Z","iopub.status.idle":"2025-11-11T23:55:13.156459Z","shell.execute_reply.started":"2025-11-11T23:55:13.151023Z","shell.execute_reply":"2025-11-11T23:55:13.155498Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:55:42.748696Z","iopub.execute_input":"2025-11-11T23:55:42.749091Z","iopub.status.idle":"2025-11-11T23:55:42.753725Z","shell.execute_reply.started":"2025-11-11T23:55:42.749062Z","shell.execute_reply":"2025-11-11T23:55:42.752893Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:56:29.963718Z","iopub.execute_input":"2025-11-11T23:56:29.964486Z","iopub.status.idle":"2025-11-11T23:56:36.882104Z","shell.execute_reply.started":"2025-11-11T23:56:29.964460Z","shell.execute_reply":"2025-11-11T23:56:36.881140Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Blog Outline: Multi-Agent Systems for Software Developers\n\n**Headline:** Supercharge Your Software: Unlock the Power of Multi-Agent Systems\n\n**Introduction Hook:** Tired of monolithic codebases that are rigid, slow to adapt, and a nightmare to maintain? Imagine a software architecture where independent, intelligent agents collaborate seamlessly to achieve complex goals. This isn't science fiction; it's the transformative power of Multi-Agent Systems (MAS), and it's about to revolutionize how you build software.\n\n---\n\n### Main Section 1: The Power of Decentralization and Autonomy\n\n*   **Breaking Down Complexity:** Learn how MAS allows you to decompose large, intricate problems into smaller, manageable units handled by specialized agents. This reduces cognitive load and improves understandability.\n*   **Resilience and Robustness:** Discover how the autonomous nature of agents makes your system more resilient to failure. If one agent falters, others can often pick up the slack or compensate, ensuring continued operation.\n*   **Scalability on Demand:** Explore how adding or removing agents can be a more efficient and dynamic way to scale your application compared to scaling a single, large system.\n\n### Main Section 2: Enhanced Problem-Solving Capabilities\n\n*   **Intelligent Collaboration:** Understand how agents can communicate, negotiate, and coordinate their actions to solve problems that would be impossible for a single entity. Think distributed AI and collective intelligence.\n*   **Adaptability and Learning:** See how individual agents can learn from their experiences and adapt their behavior, leading to a system that can evolve and improve over time without constant manual intervention.\n*   **Specialization for Optimal Performance:** Discuss how agents can be designed with specific expertise, allowing for highly optimized solutions to particular sub-problems within the larger system.\n\n### Main Section 3: Practical Applications and Developer Advantages\n\n*   **From Smart Grids to Robotics:** Explore real-world examples of MAS in action, such as optimizing energy distribution, managing complex logistics, controlling fleets of robots, and building sophisticated recommendation engines.\n*   **Streamlined Development and Maintenance:** Understand how the modular nature of MAS can lead to faster development cycles, easier debugging, and more efficient maintenance of individual agent components.\n*   **New Avenues for Innovation:** Discover how adopting MAS opens up new possibilities for creating novel and sophisticated software solutions, giving you a competitive edge.\n\n---\n\n**Concluding Thought:** Multi-Agent Systems are no longer just a theoretical concept; they are a practical and powerful paradigm shift for software development. By embracing decentralization, autonomy, and intelligent collaboration, you can build more robust, scalable, and intelligent software than ever before. It's time to move beyond the monolith and unlock the future of software with MAS.\nWriterAgent > ## Supercharge Your Software: Unlock the Power of Multi-Agent Systems\n\nTired of monolithic codebases that are rigid, slow to adapt, and a nightmare to maintain? Imagine a software architecture where independent, intelligent agents collaborate seamlessly to achieve complex goals. This isn't science fiction; it's the transformative power of Multi-Agent Systems (MAS), and it's about to revolutionize how you build software.\n\nAt its core, MAS offers a powerful alternative to traditional architectures by embracing **decentralization and autonomy**. Instead of one massive program, MAS breaks down complex problems into smaller, manageable units handled by specialized agents. This dramatically reduces cognitive load, making your systems easier to understand and develop. Furthermore, this autonomy translates to incredible **resilience and robustness**. If one agent encounters an issue, others can often compensate, ensuring your application keeps running. When it comes to scaling, MAS shines. Adding or removing agents is a far more dynamic and efficient approach than wrestling with scaling a monolithic system.\n\nBut the benefits don't stop at architecture. MAS unlocks **enhanced problem-solving capabilities**. Agents can communicate, negotiate, and coordinate, enabling them to tackle challenges far beyond the reach of a single entity ‚Äì think distributed AI in action! Individual agents can learn and adapt, allowing your system to evolve and improve over time. This specialization means each agent can be hyper-optimized for its specific task, leading to peak performance.\n\nFrom smart grids and robotics to sophisticated recommendation engines, MAS is already powering real-world innovations. For developers, this modularity means **streamlined development and maintenance**. Debugging and updating individual agent components becomes a breeze. Embracing MAS isn't just about improving existing systems; it's about opening up **new avenues for innovation**, giving you a critical competitive edge.\n\nMulti-Agent Systems are a practical paradigm shift. By adopting decentralization, autonomy, and intelligent collaboration, you can build more robust, scalable, and intelligent software than ever before. It's time to move beyond the monolith and unlock the future of software with MAS.\nEditorAgent > ## Supercharge Your Software: Unlock the Power of Multi-Agent Systems\n\nAre you tired of wrestling with monolithic codebases that feel rigid, adapt slowly, and are a constant maintenance headache? Imagine a software architecture where independent, intelligent agents collaborate seamlessly to achieve complex goals. This isn't a futuristic dream; it's the transformative power of Multi-Agent Systems (MAS), and it's poised to revolutionize how you build software.\n\nAt its heart, MAS presents a powerful alternative to traditional architectures by championing **decentralization and autonomy**. Instead of a single, massive program trying to handle everything, MAS breaks down complex problems into smaller, manageable units, each handled by a specialized agent. This approach dramatically reduces cognitive load, making your systems easier to understand and develop. Furthermore, this inherent autonomy translates to incredible **resilience and robustness**. If one agent encounters an issue, others can often compensate or take over, ensuring your application continues to function smoothly. When it comes to scaling, MAS truly shines. Adding or removing agents is a far more dynamic and efficient process than the often cumbersome task of scaling a monolithic system.\n\nBut the advantages extend well beyond architectural design. MAS unlocks significantly **enhanced problem-solving capabilities**. Agents can communicate, negotiate, and coordinate their efforts, enabling them to tackle challenges that would be insurmountable for a single entity ‚Äì a true testament to distributed intelligence in action! Individual agents can also learn and adapt, allowing your system to evolve and improve over time. This specialization means each agent can be hyper-optimized for its specific task, leading to peak performance across the board.\n\nFrom optimizing smart grids and controlling robotic fleets to powering sophisticated recommendation engines, MAS is already driving real-world innovations. For developers, this modularity translates directly into **streamlined development and maintenance**. Debugging and updating individual agent components becomes a far simpler task. Embracing MAS isn't just about refining existing systems; it's about opening up **new avenues for innovation**, providing you with a critical competitive edge in today's fast-paced technological landscape.\n\nMulti-Agent Systems represent a practical paradigm shift in software development. By adopting decentralization, autonomy, and intelligent collaboration, you can build software that is more robust, scalable, and intelligent than ever before. It's time to move beyond the limitations of the monolith and unlock the future of software with MAS.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:57:23.076200Z","iopub.execute_input":"2025-11-11T23:57:23.076992Z","iopub.status.idle":"2025-11-11T23:57:23.082009Z","shell.execute_reply.started":"2025-11-11T23:57:23.076956Z","shell.execute_reply":"2025-11-11T23:57:23.081113Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:57:31.492115Z","iopub.execute_input":"2025-11-11T23:57:31.492445Z","iopub.status.idle":"2025-11-11T23:57:31.497668Z","shell.execute_reply.started":"2025-11-11T23:57:31.492421Z","shell.execute_reply":"2025-11-11T23:57:31.496969Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:57:55.254871Z","iopub.execute_input":"2025-11-11T23:57:55.255636Z","iopub.status.idle":"2025-11-11T23:57:55.260673Z","shell.execute_reply.started":"2025-11-11T23:57:55.255609Z","shell.execute_reply":"2025-11-11T23:57:55.259794Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:58:32.583990Z","iopub.execute_input":"2025-11-11T23:58:32.584328Z","iopub.status.idle":"2025-11-11T23:58:32.589942Z","shell.execute_reply.started":"2025-11-11T23:58:32.584305Z","shell.execute_reply":"2025-11-11T23:58:32.589093Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:59:02.633065Z","iopub.execute_input":"2025-11-11T23:59:02.633412Z","iopub.status.idle":"2025-11-11T23:59:02.638744Z","shell.execute_reply.started":"2025-11-11T23:59:02.633386Z","shell.execute_reply":"2025-11-11T23:59:02.637888Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:59:59.223219Z","iopub.execute_input":"2025-11-11T23:59:59.224095Z","iopub.status.idle":"2025-11-12T00:00:11.650356Z","shell.execute_reply.started":"2025-11-11T23:59:59.224068Z","shell.execute_reply":"2025-11-12T00:00:11.649402Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nFinanceResearcher > **Tech Briefing:**\nArtificial intelligence continues to dominate headlines, with significant investments in AI infrastructure and new AI-powered services emerging. Companies like Google are expanding data center capacity, and startups are attracting substantial funding for AI development. The market is seeing intense competition, with established players and new entrants vying for dominance in AI hardware and software.\n\n**Health Briefing:**\nRecent developments include discussions around the long-term effects of melatonin on heart health and the ongoing debate on healthcare costs and policy. The FDA is making changes to drug approvals, and there's a focus on improving adherence to treatments like oral oncolytics. Public health initiatives are also expanding, with libraries becoming community health hubs.\n\n**Finance Briefing:**\nThe IPO market shows signs of reawakening, with banks preparing for a surge of offerings. Discussions around sustainable finance and the role of multilateral development banks in adaptation finance are prominent. Regulatory bodies are also releasing new strategies and consulting on various financial products, indicating a dynamic environment for investment and financial services.\n\n**Fintech Trends:**\n\n1.  **Embedded Finance:** This trend integrates financial services directly into non-financial platforms, offering seamless user experiences. Market implication: Increased customer loyalty and new revenue streams for businesses. Future outlook: Widespread adoption across e-commerce, SaaS, and other industries.\n2.  **AI and Machine Learning:** AI is revolutionizing everything from fraud detection to personalized financial advice. Market implication: Enhanced efficiency, improved risk management, and hyper-personalized customer journeys. Future outlook: Deeper integration, driving predictive analytics and automated decision-making.\n3.  **Decentralized Finance (DeFi):** DeFi aims to recreate traditional financial systems on blockchain technology, offering greater transparency and accessibility. Market implication: Disruption of traditional intermediaries, potential for lower transaction costs. Future outlook: Maturation of platforms, regulatory clarity, and broader institutional adoption.\nHealthResearcher > Here's a summary of recent breakthroughs in Tech, Health, and Finance:\n\n**Technology:** Agentic AI, capable of autonomously planning and executing tasks, is emerging rapidly, with potential applications ranging from virtual coworkers to complex workflow automation. This, along with advancements in robotics and autonomous systems, points to a future where technology is more adaptive and collaborative.\n\n**Health:** Gene therapy continues to show immense promise, with successful treatments for genetic diseases and potential applications in heart disease and cystic fibrosis. Advances in 3D bioprinting are enabling the creation of tissues and cells, paving the way for future organ printing for drug testing and transplantation. Furthermore, new gene therapies are emerging for hearing restoration and treating certain cancers.\n\n**Finance:** The financial sector is being reshaped by AI and machine learning for enhanced risk assessment and user experience. Blockchain and DeFi offer decentralized and secure platforms, streamlining processes and improving data reliability. Breakthroughs also include advancements in digital asset and crypto banking, alongside innovative mobile banking solutions offering comprehensive features.\n\n**Timelines:**\n*   **Agentic AI:** Practical applications are already emerging, with widespread adoption expected within the next 1-3 years.\n*   **3D Bioprinting/Organ Printing:** While cell and tissue printing is advancing, full organ printing for transplantation is likely 5-10 years away.\n*   **AI/ML in Finance:** These technologies are currently being integrated, with significant impact expected within the next 1-2 years.\nTechResearcher > **AI/ML Trends: A Concise Executive Briefing**\n\n**Key Developments:**\n\n1.  **Generative AI Expansion:** Generative AI is moving beyond text to create diverse content like graphics, video, and music. Companies like OpenAI (ChatGPT), Google (Gemini, Imagen, Muse), and Anthropic (Claude) are at the forefront, with tools like Synthesia and Runway ML leading in video and image generation. This trend enhances artistic expression and practical applications.\n2.  **Agentic AI & Automation:** The rise of \"virtual coworkers\" or agentic AI involves systems that can autonomously plan and execute multi-step workflows. This is rapidly emerging in enterprise and consumer tech, with potential impacts on autonomous systems and new human-machine collaboration models.\n3.  **Retrieval-Augmented Generation (RAG) & Edge Computing:** RAG enhances AI by allowing models to access external data for more accurate responses, crucial for sectors needing precise information. Simultaneously, edge computing is growing, processing data closer to the source for real-time insights, particularly impacting healthcare with wearable devices.\n\n**Companies Involved:** Major players include OpenAI, Google, Microsoft, Anthropic, Meta, IBM, and numerous startups like Synthesia, Runway ML, xAI, and Thinking Machine Labs.\n\n**Potential Impact:** These advancements promise increased productivity, enhanced creativity, and more sophisticated automation across industries. However, they also raise concerns regarding job displacement, data privacy, ethical implications, and the need for robust AI governance and regulation.\nAggregatorAgent > ## Executive Briefing: AI Drives Transformation Across Tech, Health, and Finance\n\n**Key Takeaway:** Artificial Intelligence is the dominant force reshaping all three sectors, promising unprecedented advancements in automation, personalization, and creative capabilities, while also necessitating careful consideration of ethical implications and governance.\n\n**Technology:** The AI landscape is rapidly evolving with **Generative AI** expanding beyond text to create diverse content. A significant development is **Agentic AI**, poised to act as \"virtual coworkers\" and automate complex workflows within 1-3 years. Advancements in **Retrieval-Augmented Generation (RAG)** and **edge computing** are also enhancing AI's precision and real-time processing capabilities, especially in healthcare with wearable devices.\n\n**Health:** AI's influence is evident in the advancements of **gene therapy**, offering new treatments for genetic diseases, and **3D bioprinting**, which holds promise for future organ printing within 5-10 years. While AI is improving drug adherence and enabling new public health initiatives, discussions around healthcare costs and policy remain critical.\n\n**Finance:** AI and machine learning are revolutionizing financial services through enhanced risk assessment and personalized experiences, with significant impact expected within 1-2 years. **Embedded Finance** is integrating financial services seamlessly into non-financial platforms, and **Decentralized Finance (DeFi)** continues to gain traction, offering more transparent and accessible financial systems. The IPO market is showing signs of recovery, alongside a focus on sustainable finance.\n\n**Cross-Sector Impact:** The common thread is AI's capability to drive efficiency, innovation, and new collaborative models. However, the rapid development of these technologies also raises important questions about data privacy, ethical considerations, and the need for robust governance and regulation.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:04:01.358240Z","iopub.execute_input":"2025-11-12T00:04:01.359069Z","iopub.status.idle":"2025-11-12T00:04:01.363850Z","shell.execute_reply.started":"2025-11-12T00:04:01.359034Z","shell.execute_reply":"2025-11-12T00:04:01.363101Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:04:41.671958Z","iopub.execute_input":"2025-11-12T00:04:41.672788Z","iopub.status.idle":"2025-11-12T00:04:41.677662Z","shell.execute_reply.started":"2025-11-12T00:04:41.672760Z","shell.execute_reply":"2025-11-12T00:04:41.676767Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:06:33.632867Z","iopub.execute_input":"2025-11-12T00:06:33.633214Z","iopub.status.idle":"2025-11-12T00:06:33.638532Z","shell.execute_reply.started":"2025-11-12T00:06:33.633193Z","shell.execute_reply":"2025-11-12T00:06:33.637574Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:07:21.271413Z","iopub.execute_input":"2025-11-12T00:07:21.271700Z","iopub.status.idle":"2025-11-12T00:07:21.277458Z","shell.execute_reply.started":"2025-11-12T00:07:21.271681Z","shell.execute_reply":"2025-11-12T00:07:21.276640Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:07:58.712443Z","iopub.execute_input":"2025-11-12T00:07:58.712743Z","iopub.status.idle":"2025-11-12T00:07:58.718327Z","shell.execute_reply.started":"2025-11-12T00:07:58.712720Z","shell.execute_reply":"2025-11-12T00:07:58.717495Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:08:06.696947Z","iopub.execute_input":"2025-11-12T00:08:06.697239Z","iopub.status.idle":"2025-11-12T00:08:15.307264Z","shell.execute_reply.started":"2025-11-12T00:08:06.697217Z","shell.execute_reply":"2025-11-12T00:08:15.306663Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias traced the salt-worn lines on the old oak table. For thirty years, the rhythmic crash of waves had been his only company in the lighthouse. Tonight, however, a different kind of light pulsed from the sea chest he‚Äôd finally pried open. Inside, nestled amongst faded charts, lay a parchment unlike any he‚Äôd seen. It glowed with an internal, ethereal blue, the lines upon it shifting and reforming like liquid moonlight. He ran a calloused finger over a symbol that pulsed brighter than the rest. It wasn‚Äôt any constellation he knew, nor any marker from any earthly sea. The map hummed softly, a siren song in the silent tower, and Elias felt a pull, as ancient and irresistible as the tide itself, towards the unknown.\nCriticAgent > The story is intriguing and sets a strong atmosphere, but it feels incomplete and could benefit from further development.\n\nHere are a few suggestions for improvement:\n\n1.  **Develop Elias's internal reaction and motivation:** While his loneliness is established, his reaction to the map could be more detailed. What are his immediate thoughts and feelings beyond the \"pull\"? Is he afraid, excited, skeptical? Does this discovery connect to any past dreams or regrets? Expanding on his internal state will make his decision to follow the map more compelling.\n\n2.  **Flesh out the map's mystery:** The description of the map is evocative, but adding a touch more specificity, even if it remains mysterious, could deepen the intrigue. For instance, what kind of symbols are on it? Do they vaguely resemble something familiar but alien, or are they entirely abstract? What does the \"siren song\" of the hum suggest? A hint at the nature of the unknown, even if cryptic, could enhance the allure.\n\n3.  **Consider hinting at the immediate next step:** The story ends with Elias feeling the pull. While this creates suspense, a brief foreshadowing of what he might do *next* ‚Äì perhaps looking out at the sea with a new determination, or reaching for an old coat ‚Äì would give the ending a slightly more solid foundation and suggest the story is on the cusp of a larger adventure.\nRefinerAgent > Elias traced the salt-worn lines on the old oak table, his knuckles white. For thirty years, the rhythmic crash of waves against the lighthouse had been his sole companion, a monotonous lullaby to his solitude. Tonight, however, a different kind of light pulsed from the sea chest he‚Äôd finally pried open. Inside, nestled amongst faded charts of familiar coastlines, lay a parchment unlike any he‚Äôd ever encountered. It glowed with an internal, ethereal blue, the lines upon it shifting and reforming like liquid moonlight.\n\nA tremor ran through Elias, a mixture of awe and a primal fear he hadn‚Äôt felt since his first storm at sea. This was no earthly artifact. He ran a calloused finger over a symbol that pulsed brighter than the rest‚Äîa spiral that seemed to writhe and beckon. It wasn‚Äôt any constellation he knew, nor any marker from any earthly sea. Were those‚Ä¶ eyes within the spiral? Or perhaps stylized waves of an alien ocean? The map hummed softly, a low thrum that resonated in his very bones, a siren song that spoke not of danger, but of profound, forgotten truths. It whispered of a longing Elias hadn't dared to acknowledge, a yearning for something beyond the predictable horizon, a quiet regret for the life unlived.\n\nThe hum deepened, and Elias felt a pull, as ancient and irresistible as the tide itself, towards the unknown. He looked from the glowing parchment to the dark, churning sea outside his window. Thirty years of predictable solitude suddenly felt like a cage. He took a deep, steadying breath, the scent of brine and ozone filling his lungs. He didn't know where the map led, or what lay at its destination, but for the first time in decades, Elias felt truly awake. His gaze hardened with a newfound resolve. He turned, his eyes scanning the familiar confines of his small room, searching for the worn leather satchel that had accompanied him on his youthful, now-abandoned, seafaring dreams. The adventure, it seemed, was finally calling him home.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}